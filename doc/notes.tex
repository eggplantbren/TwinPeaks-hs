\documentclass[a4paper, 12pt]{article}
\usepackage{amsmath}
\usepackage{color}
\usepackage{dsfont}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage[left=2cm, right=2cm, bottom=3cm, top=2cm]{geometry}
\usepackage{natbib}
\usepackage{microtype}

\definecolor{orange}{rgb}{1, 0.5, 0}
\definecolor{darkgreen}{rgb}{0, 0.5, 0}
\definecolor{darkred}{rgb}{0.7, 0, 0}
\newcommand{\btheta}{\boldsymbol{\theta}}

\title{Notes}
\author{Brendon J. Brewer}
\date{}
\begin{document}
\maketitle

% Need this after the abstract
\setlength{\parindent}{0pt}
\setlength{\parskip}{8pt}

\section*{A property of Nested Sampling}
Consider the implied prior for $L$, denoted $\pi(L)$. This is
a probability distribution over the real line.
NS sequence rectifies $\pi$ to give you the distribution
\begin{align}
p_{\rm NS}(L) &= C \frac{\pi(L)}{X(L)}
\end{align}
which will be proper in practice as the run has to terminate.

The amount of prior mass above any specified likelihood value
$\ell$ is
\begin{align}
X(\ell) &= \int_{\ell}^{\infty} \pi(L) \, dL 
\end{align}
which is the normalisation constant of a constrained prior with
threshold $\ell$.
NS gives us the opportunity to measure this for any given
value of $\ell$. Consider the KL divergence from $p_{\rm NS}$ to
the constrained prior:
\begin{align}
D_{\rm KL}(p_\ell \,||\, \pi)
  &= \int_{\ell}^{\infty} \pi(L)
           \log\left[\frac{X(L)}{C}\right] \, dL
\end{align}


\section*{TwinPeaks}
Denote the two scalars by $L_1(\btheta)$ and $L_2(\btheta)$.
Consider a `constrained prior' type distribution:
\begin{align}
p(\btheta | L_1^*, L_2^*) &\propto
    \left\{
        \begin{array}{lr}
            \pi(\btheta), & L_1(\btheta) > L_1^* \textnormal{ and }
                            L_2(\btheta) > L_2^* \\
            0             & \textnormal{otherwise}.
        \end{array}
    \right.
\end{align}

%Suppose there are $N$ particles,


\end{document}

